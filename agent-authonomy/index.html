<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <title>AI Agent Autonomy</title>

  <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
  <meta name="author" content="Hakim El Hattab">

  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <link rel="stylesheet" href="libs/reveal.js/4.3.1/reset.css">
  <link rel="stylesheet" href="libs/reveal.js/4.3.1/reveal.css">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

  <!-- highlight Theme -->
  
  <link rel="stylesheet" href="libs/highlight.js/11.3.1/styles/monokai.min.css">
  
	
		
	<link rel="stylesheet" href="libs/reveal.js/4.3.1/plugin/chalkboard/style.css">
	
	
	
  <link rel="stylesheet" href="libs/reveal.js/4.3.1/plugin/customcontrols/style.css">
  
	



  <!-- Revealjs Theme -->
  
  <link rel="stylesheet" href="libs/reveal.js/4.3.1/theme/solarized.css" id="theme">
  
  

  <link rel="stylesheet" href="libs/styles/tasklist.css">
	<link rel="stylesheet" href="libs/styles/iota.css">
	<link rel="stylesheet" href="libs/styles/layout.css">


  <!-- Revealjs Theme -->
  

   <!-- css list -->
	

   

</head>

<body>

   

  <div class="reveal">

    <!-- Any section element inside of this container is displayed as a slide -->
    <div class="slides">

      


    
        <section >
            
            <h1>AI Agent Autonomy</h1>
<h2>Understanding the Spectrum of Intelligence</h2>

            </section>
    



    
        <section >
            
            <h2>What is AI Agent Autonomy?</h2>
<p><strong>Autonomy</strong> refers to an AI agent’s ability to:</p>
<ul>
<li><strong>Act independently</strong> without constant human intervention</li>
<li><strong>Make decisions</strong> based on environmental feedback</li>
<li><strong>Adapt strategies</strong> to achieve goals</li>
<li><strong>Learn and improve</strong> from experience</li>
</ul>
<p>The more autonomous an agent, the less human oversight it requires.</p>

            </section>
    



    
        <section >
            
            <h1>The SPAR Framework</h1>
<h2>How AI Agents Operate</h2>

            </section>
    



    
        <section >
            
            <h2>SPAR Overview</h2>
<p><img src="./spar.png" alt="spar"></p>
<p><strong>How AI Agents Take Action:</strong></p>
<p>The SPAR cycle enables agents to operate autonomously by continuously sensing, planning, acting, and reflecting.</p>

            </section>
    



    
        <section >
            
            <h2>Sense</h2>
<h3>Gathering Information</h3>
<ul>
<li><strong>Gather data</strong> from multiple sources</li>
<li><strong>Detect changes</strong> in the environment</li>
<li><strong>Maintain context awareness</strong></li>
<li><strong>Process inputs</strong> from various modalities</li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Plan</h2>
<h3>Strategic Thinking</h3>
<ul>
<li><strong>Engage in sophisticated reasoning</strong> to develop strategies</li>
<li><strong>Create step-by-step plans</strong> for goal achievement</li>
<li><strong>Coordinate resources</strong> effectively</li>
<li><strong>Adapt to constraints</strong> and opportunities</li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Act</h2>
<h3>Execution Phase</h3>
<ul>
<li><strong>Use available tools</strong> to carry out planned actions</li>
<li><strong>Send messages</strong> and communicate with systems</li>
<li><strong>Update systems</strong> and databases</li>
<li><strong>Execute complex workflows</strong></li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Reflect</h2>
<h3>Learning and Improvement</h3>
<ul>
<li><strong>Learn and adapt</strong> from experience</li>
<li><strong>Analyze performance</strong> metrics</li>
<li><strong>Refine approaches</strong> for future tasks</li>
<li><strong>Build knowledge</strong> from outcomes</li>
</ul>

            </section>
    



    
        <section >
            
            <h1>The Autonomy Framework</h1>
<h2>Six Levels of AI Independence</h2>

            </section>
    



    
        <section >
            
            <h2>The Autonomy Pyramid</h2>
<p><img src="./authonomy-framework.png" alt="Autonomy Pyramid"></p>
<p><strong>Higher levels = Greater autonomy</strong></p>

            </section>
    



    
        <section >
            
            <h2>Autonomy as Design Choice</h2>
<p>Designing AI systems requires <strong>intentional decisions</strong> about autonomy level:</p>
<p><strong>Business Considerations:</strong></p>
<ul>
<li>Risk tolerance and safety requirements</li>
<li>Regulatory compliance needs</li>
<li>User trust and acceptance</li>
</ul>
<p><strong>Technical Constraints:</strong></p>
<ul>
<li>Available data and compute resources</li>
<li>System complexity requirements</li>
<li>Integration capabilities</li>
</ul>

            </section>
    



    
        <section >
            
            <h1>Level 0: Manual Operations</h1>
<h2>Human-Only Control</h2>

            </section>
    



    
        <section >
            
            <h2>Level 0: Overview</h2>
<h3>Manual Operations</h3>
<p><strong>AI Agent Analogy:</strong> A basic calculator - requires human input for every operation</p>
<p><strong>Key Characteristics:</strong></p>
<ul>
<li>Humans perform all tasks without automation</li>
<li>Basic digital tools (spreadsheets, email)</li>
<li>Manual processing only</li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Level 0: SPAR Analysis</h2>
<h3>Not Applicable</h3>
<p><strong>SPAR Capabilities:</strong> Not Applicable</p>
<ul>
<li>No automated sensing, planning, acting, or reflecting</li>
<li>All cognitive work performed by humans</li>
<li>Digital tools serve only as passive instruments</li>
</ul>

            </section>
    



    
        <section >
            
            <h1>Level 1: Rule-Based Automation</h1>
<h2>Simple Automation</h2>

            </section>
    



    
        <section >
            
            <h2>Level 1: Overview</h2>
<h3>Rule-Based Automation</h3>
<p><strong>AI Agent Analogy:</strong> A chatbot with predefined responses - follows scripts but can’t adapt</p>
<p><strong>Key Characteristics:</strong></p>
<ul>
<li>Simple automation follows fixed rules</li>
<li>Basic automation tools (RPA, simple scripts)</li>
<li>Predefined triggers and structured data</li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Level 1: SPAR Analysis</h2>
<h3>Basic Automation Cycle</h3>
<p><strong>SPAR Capabilities:</strong></p>
<ul>
<li><strong>Sensing:</strong> Predefined triggers and simple data inputs</li>
<li><strong>Planning:</strong> Simple if-then rules and decision trees</li>
<li><strong>Acting:</strong> Deterministic actions with fixed responses</li>
<li><strong>Reflecting:</strong> Basic logging only, no learning</li>
</ul>

            </section>
    



    
        <section >
            
            <h1>Level 2: Intelligent Process Automation</h1>
<h2>Smart Automation</h2>

            </section>
    



    
        <section >
            
            <h2>Level 2: Overview</h2>
<h3>Intelligent Process Automation</h3>
<p><strong>AI Agent Analogy:</strong> A smart email assistant - can categorize emails and suggest responses but needs approval</p>
<p><strong>Key Characteristics:</strong></p>
<ul>
<li>AI combines automation with cognitive abilities</li>
<li>Machine learning, NLP, computer vision, RPA</li>
<li>Semi-structured data from multiple sources</li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Level 2: SPAR Analysis</h2>
<h3>Enhanced Processing</h3>
<p><strong>SPAR Capabilities:</strong></p>
<ul>
<li><strong>Sensing:</strong> Multi-source data processing and pattern recognition</li>
<li><strong>Planning:</strong> Basic AI models for classification and prediction</li>
<li><strong>Acting:</strong> Sophisticated actions with error handling</li>
<li><strong>Reflecting:</strong> Performance monitoring, no adaptation</li>
</ul>

            </section>
    



    
        <section >
            
            <h1>Level 3: Agentic Workflows</h1>
<h2>Reasoning Agents</h2>

            </section>
    



    
        <section >
            
            <h2>Level 3: Overview</h2>
<h3>Agentic Workflows</h3>
<p><strong>AI Agent Analogy:</strong> A research assistant - can gather information, analyze data, and create reports but needs guidance on complex decisions</p>
<p><strong>Key Characteristics:</strong></p>
<ul>
<li>Agents generate content, plan, reason, and adapt</li>
<li>Large language models, memory systems, content generation</li>
<li>Advanced natural language understanding</li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Level 3: SPAR Analysis</h2>
<h3>Intelligent Reasoning</h3>
<p><strong>SPAR Capabilities:</strong></p>
<ul>
<li><strong>Sensing:</strong> Advanced NLU and context awareness</li>
<li><strong>Planning:</strong> Foundation model reasoning and workflow orchestration</li>
<li><strong>Acting:</strong> Chaining tools and multi-step task execution</li>
<li><strong>Reflecting:</strong> Limited short-term feedback and long-term memory</li>
</ul>

            </section>
    



    
        <section >
            
            <h1>Level 4: Semi-Autonomous Agents</h1>
<h2>Strategic Independence</h2>

            </section>
    



    
        <section >
            
            <h2>Level 4: Overview</h2>
<h3>Semi-Autonomous Agents</h3>
<p><strong>AI Agent Analogy:</strong> A specialized AI consultant - operates independently in its domain of expertise, adapting strategies based on outcomes</p>
<p><strong>Key Characteristics:</strong></p>
<ul>
<li>Agents work autonomously within defined expertise</li>
<li>Advanced reasoning, real-time adaptation, causal reasoning</li>
<li>Multi-modal perception of diverse inputs</li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Level 4: SPAR Analysis</h2>
<h3>Advanced Autonomy</h3>
<p><strong>SPAR Capabilities:</strong></p>
<ul>
<li><strong>Sensing:</strong> Multi-modal perception and interpretation</li>
<li><strong>Planning:</strong> Dynamic strategies for complex, evolving tasks</li>
<li><strong>Acting:</strong> Autonomous tool usage and intelligent error recovery</li>
<li><strong>Reflecting:</strong> Context retention across sessions, learns from experience</li>
</ul>

            </section>
    



    
        <section >
            
            <h1>Level 5: Fully Autonomous Agents</h1>
<h2>Complete Independence</h2>

            </section>
    



    
        <section >
            
            <h2>Level 5: Overview</h2>
<h3>Fully Autonomous Agents</h3>
<p><strong>AI Agent Analogy:</strong> An AI scientist - can conduct research, form hypotheses, design experiments, and discover new knowledge across any domain</p>
<p><strong>Key Characteristics:</strong></p>
<ul>
<li>AI systems handle any task, cross-domain learning</li>
<li>Sophisticated memory systems, advanced learning mechanisms</li>
<li>Complete environmental awareness</li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Level 5: SPAR Analysis</h2>
<h3>Complete Autonomy</h3>
<p><strong>SPAR Capabilities:</strong></p>
<ul>
<li><strong>Sensing:</strong> Complete environmental awareness and goal formulation</li>
<li><strong>Planning:</strong> Advanced reasoning and original problem-solving</li>
<li><strong>Acting:</strong> Full autonomy in tool selection and execution</li>
<li><strong>Reflecting:</strong> Continuous self-improvement, robust long-term memory</li>
</ul>

            </section>
    



    
        <section >
            
            <h1>Key Takeaways</h1>
<h2>Implementation Insights</h2>

            </section>
    



    
        <section >
            
            <h2>The Autonomy Spectrum</h2>
<p><strong>Key Insights:</strong></p>
<ul>
<li>Higher autonomy = less human intervention required</li>
<li>Higher autonomy = more complexity and more AI LLM involvement</li>
<li>Higher autonomy = more hallucinations</li>
<li>Design choice depends on specific use case needs</li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Implementation Considerations</h2>
<p><strong>Best Practices:</strong></p>
<ul>
<li>Start with lower levels and gradually increase autonomy</li>
<li>Balance capability requirements with risk management</li>
<li>Consider user acceptance and regulatory constraints</li>
<li>Design appropriate human oversight mechanisms</li>
</ul>

            </section>
    



    
        <section >
            
            <h2>Thank You</h2>
<p><strong>Questions &amp; Discussion</strong></p>
<p><em>Understanding AI agent autonomy helps us build more effective and trustworthy AI systems</em></p>

            </section>
    


    </div>


  </div>

  <div class="line top"></div>
  <div class="line bottom"></div>
  <div class="line left"></div>
  <div class="line right"></div>

  <script src="libs/reveal.js/4.3.1/reveal.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/notes/notes.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/markdown/markdown.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/highlight/highlight.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/math/math.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/fullscreen/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/animate/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/animate/svg.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/Chart.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/d3/d3.v3.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/d3.patch.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/d3/queue.v1.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/d3/topojson.v1.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/function-plot.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/customcontrols/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/embed-tweet/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/chart/chart.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/chart/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/verticator/verticator.js"></script>

<script src="libs/reveal.js/4.3.1/plugin/zoom/zoom.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/search/search.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/menu/menu.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/chalkboard/plugin.js"></script>

<!--	<script src="libs/reveal.js/4.3.1/plugin/audio-slideshow/plugin.js"></script>  -->
<!--	<script src="libs/reveal.js/4.3.1/plugin/audio-slideshow/recorder.js"></script>-->
<!--	<script src="libs/reveal.js/4.3.1/plugin/audio-slideshow/RecordRTC.js"></script>-->

  

<script>
  const printPlugins = [
      RevealNotes,
      RevealHighlight,
      RevealMath.MathJax3,
      RevealAnimate,
      RevealChalkboard, 
			RevealEmbedTweet,
			RevealChart,
		];

		const plugins =  [...printPlugins,
		RevealZoom, 
		RevealSearch, 
				RevealMarkdown, 
				RevealMenu, 
				RevealFullscreen,
				RevealAnything,
				//RevealAudioSlideshow,
				//RevealAudioRecorder,
				RevealCustomControls, 
				// poll
				// question
				// seminar
				Verticator 
				 ]


		// Also available as an ES module, see:
		// https://revealjs.com/initialization/
		Reveal.initialize({
			controls: true,
      controlsTutorial: true,
      controlsLayout: 'bottom-right',
      controlsBackArrows: 'faded',
      progress: true,
      slideNumber: false,
      //#showSlideNumber "all" "print" "speaker"
      hash: true, //# hash: false,
      //# respondToHashChanges: true,
      //# history: false,
      keyboard: true,
      //#keyboardCondition: null,
      overview: true,
      center: true,
      touch: true,
      loop: false,
      rtl: false,
      //#navigationMode: 'default', linear grid
      shuffle: false,
      fragments: true,
      fragmentInURL: false,
      embedded: false,
      help: true,
      //#pause: true
      showNotes: false,
      autoPlayMedia: false, // TODO fix this to a nullable value
      //#preloadIframes: null. true false
      //#autoAnimate: true
      //#autoAnimateMatcher: null,
      //#autoAnimateEasing: 'ease',
      //autoAnimateDuration: 1.0,
      //#autoAnimateUnmatched: true
      //#autoAnimateStyles: []
      autoSlide: 0, // TODO fix this to a falseable value
      autoSlideStoppable: true,
      autoSlideMethod: '0',
      defaultTiming: 120,
      mouseWheel: false,
      //#previewLinks: false
      //#postMessage: true, // TODO : this can cause issues with the vscode api ???
      //#postMessageEvents: false,
      //#focusBodyOnPageVisibilityChange: true,
      transition: 'slide',
      transitionSpeed: 'default',
      backgroundTransition: 'fade',
      //#pdfMaxPagesPerSlide: Number.POSITIVE_INFINITY,
      //#pdfSeparateFragments: true,
      //#pdfPageHeightOffset: -1,
      viewDistance: 3,
      //#mobileViewDistance: 2,
      display: 'block',
      //#hideInactiveCursor: true,
      //#hideCursorTime: 5000

      // Parallax Background
      parallaxBackgroundImage: '',
      parallaxBackgroundSize: '',
      parallaxBackgroundHorizontal: 0,
      parallaxBackgroundVertical: 0,

      //Presentation Size
      width: 960,
			height: 700,
			margin: 0.04,
      minScale: 0.2,
      maxScale: 2,
      disableLayout: false,

      audio: {
        prefix: 'audio/', // audio files are stored in the "audio" folder
        suffix: '.ogg', // audio files have the ".ogg" ending
        textToSpeechURL: null, // the URL to the text to speech converter
        defaultNotes: false, // use slide notes as default for the text to speech converter
        defaultText: false, // use slide text as default for the text to speech converter
        advance: 0, // advance to next slide after given time in milliseconds after audio has played, use negative value to not advance
        autoplay: false, // automatically start slideshow
        defaultDuration: 5, // default duration in seconds if no audio is available
        defaultAudios: true, // try to play audios with names such as audio/1.2.ogg
        playerOpacity: 0.05, // opacity value of audio player if unfocused
        playerStyle: 'position: fixed; bottom: 4px; left: 25%; width: 50%; height:75px; z-index: 33;', // style used for container of audio controls
        startAtFragment: false, // when moving to a slide, start at the current fragment or at the start of the slide
      },
      
      chalkboard: { // font-awesome.min.css must be available
        //src: "chalkboard/chalkboard.json",
        storage: "chalkboard-demo",
      },
      
			customcontrols: {
					controls: [
      						{
						  id: 'toggle-overview',
						  title: 'Toggle overview (O)',
						  icon: '<i class="fa fa-th"></i>',
						  action: 'Reveal.toggleOverview();'
						}
						,
      {
        icon: '<i class="fa fa-pen-square"></i>',
        title: 'Toggle chalkboard (B)',
        action: 'RevealChalkboard.toggleChalkboard();'
      },
      {
        icon: '<i class="fa fa-pen"></i>',
        title: 'Toggle notes canvas (C)',
        action: 'RevealChalkboard.toggleNotesCanvas();'
      }
      
				]
			},
			chart: {
					defaults: { 
						color: 'lightgray', // color of labels
						scale: { 
							beginAtZero: true, 
							ticks: { stepSize: 1 },
							grid: { color: "lightgray" } , // color of grid lines
						},
					},
					line: { borderColor: [ "rgba(20,220,220,.8)" , "rgba(220,120,120,.8)", "rgba(20,120,220,.8)" ], "borderDash": [ [5,10], [0,0] ] }, 
					bar: { backgroundColor: [ "rgba(20,220,220,.8)" , "rgba(220,120,120,.8)", "rgba(20,120,220,.8)" ]}, 
					pie: { backgroundColor: [ ["rgba(0,0,0,.8)" , "rgba(220,20,20,.8)", "rgba(20,220,20,.8)", "rgba(220,220,20,.8)", "rgba(20,20,220,.8)"] ]},
					radar: { borderColor: [ "rgba(20,220,220,.8)" , "rgba(220,120,120,.8)", "rgba(20,120,220,.8)" ]}, 
			},
			math: {
				mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				// pass other options into `MathJax.Hub.Config()`
				TeX: { Macros: { RR: "{\\bf R}" } }
				},
				anything: [ 
				{
		className: "plot",
		defaults: {width:500, height: 500, grid:true},
		initialize: (function(container, options){ options.target = "#"+container.id; functionPlot(options) })
	 },
	 {
		className: "chart",  
		initialize: (function(container, options){ container.chart = new Chart(container.getContext("2d"), options);  })
	 },
	 {
		className: "anything",
		initialize: (function(container, options){ if (options && options.initialize) { options.initialize(container)} })
	 },
					],
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: (window.location.search.match(/print-pdf/gi) ? printPlugins : plugins ) 
		});
			


	    // Change chalkboard theme : 
		function changeTheme(input) {
			var config = {};
			config.theme = input.value;
			Reveal.getPlugin("RevealChalkboard").configure(config);
			input.blur();
		}

		// // Handle the message inside the webview
        // window.addEventListener('message', event => {

        //     const message = event.data; // The JSON data our extension sent

        //     switch (message.command) {
        //         case 'refactor':
        //             Reveal.toggleHelp();
        //     }
        // });

		if (window.location.search.match(/print-pdf-now/gi)) {
      		setTimeout(() => {
				window.print();
			  }, 2500);
			
    }
</script>

</body>

</html>